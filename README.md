These projects cover the fundamentals of modern statistical machine
learning. Lectures will cover the theoretical foundation and algorithmic
details of representative topics including probabilities and decision
theory, regression, classification, graphical models, mixture models,
clustering, expectation maximization, hidden Markov models, and weak
learning.

Achieved Objectives: • Explore and implement basic machine-learning
methods and algorithms. • Demonstrate how to adapt mathematical
principles in the service of basic machine-learning methods and
algorithms. • Explore and discuss the broader context in which machine
learning plays a role in current science and technology.

Concepts Used:

• Curse of Dimensionality • Feature Selection (IG) • Feature Projection
• Clustering (Flat) • Clustering (Hierarchical) • Fundamental Supervised
Concepts • Linear Regression • Gradient-Based Learning • Introduction to
Classification\
• Nearest Neighbors • Inference • Naïve Bayes\
• Decision Trees • Support Vector Machines\
• Logistic Regression • Artificial Neural Networks\
• Ensemble Methods
